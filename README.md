# U-Net Segmentation from Scratch ğŸ§ 
![Python](https://img.shields.io/badge/python-3.9-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![PyTorch](https://img.shields.io/badge/PyTorch-1.13.1-%23EE4C2C?logo=pytorch)
![Model](https://img.shields.io/badge/Model-U--Net-brightgreen)


This is a deep learning project for binary image segmentation using a U-Net model built from scratch with PyTorch.

The project includes:
- âœ… A custom implementation of the U-Net architecture  
- ğŸ“¦ Dataset loading and preprocessing with Albumentations  
- ğŸ› ï¸ A full training pipeline with validation and metrics  
- ğŸ§ª Inference code to predict masks for unseen images

---

## ğŸ¯ Competition Source  
This project was built using the dataset from the [Carvana Image Masking Challenge on Kaggle](https://www.kaggle.com/competitions/carvana-image-masking-challenge).

---

## âš™ï¸ Training Setup

Due to hardware limitations (Mac M1 Air), the images were resized from their original resolution to **240x160** during training and inference.  
Despite the downscaling, the model achieved strong results:

- **Accuracy:** 99.44%  
- **Dice Score:** 0.986  

> ğŸ“Œ *Note:* You can increase the image size (e.g. 512x512 or original size) for even better performance on higher-end machines.

---
## ğŸ–¼ï¸ Sample Predictions

Here are some example predictions generated by the model:

| Ground Truth  | Predicted Mask |
|-------------|----------------|
| ![Mask](saved_images/mask_0.png) | ![Input](saved_images/pred_0.png)|


> You can find all predicted masks inside the `saved_images/` folder after running `predict.py`.
--
## ğŸ“ Folder Structure

Here's a quick overview of the main files and folders in the project:

```bash

â”œâ”€â”€ data/                         # Folder containing training and validation images & masks
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train_masks/
â”‚   â”œâ”€â”€ data_validation/
â”‚   â””â”€â”€ data_validation_masks/
â”œâ”€â”€ saved_images/                # Output folder for predicted masks
â”œâ”€â”€ Model.py                     # U-Net model architecture
â”œâ”€â”€ dataset.py                   # Custom Dataset class
â”œâ”€â”€ train.py                     # Training pipeline
â”œâ”€â”€ test.py                      # Evaluation or prediction script
â”œâ”€â”€ utils.py                     # Helper functions (metrics, plotting, etc.)
â”œâ”€â”€ requirements.txt             # Python dependencies
```

## ğŸ”— Pretrained Weights

Download the pretrained model checkpoint here: [Google Drive link](https://drive.google.com/file/d/1vhwpv_wTyPrgY_KHs4jMepkcNRaUlvwR/view?usp=share_link) 


## ğŸ“¦ Dataset

You can download the dataset required for training and validation from the link below:  ğŸ‘‰ [Download Dataset from Google Drive](https://drive.google.com/file/d/1H3MWmNQTnY3nssauDrntniGEhkTMk_eD/view?usp=share_link)

> ğŸ’¡ Make sure to extract the dataset and place it in the `data/` directory.

## ğŸš€ How to Run

1. **Install dependencies**
```bash
pip install -r requirements.txt
```

2. **Train the model**
```bash
python train.py
```
3. **Run inference on test image**
```bash
python test.py
```
4. **Output**
  ğŸ–¼ï¸ The predicted masks will be saved in the saved_images/ folder

## ğŸ’¬ Notes
	â€¢	The model uses BCEWithLogitsLoss for binary segmentation.
	â€¢	Mixed precision training (AMP) is supported for faster training on GPUs.
	â€¢	Image augmentation is applied using Albumentations.



