# U-Net Segmentation from Scratch 🧠
![Python](https://img.shields.io/badge/python-3.9-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-1.13.1-%23EE4C2C?logo=pytorch)
![Model](https://img.shields.io/badge/Model-U--Net-brightgreen)


This is a deep learning project for binary image segmentation using a U-Net model built from scratch with PyTorch.

The project includes:
- ✅ A custom implementation of the U-Net architecture  
- 📦 Dataset loading and preprocessing with Albumentations  
- 🛠️ A full training pipeline with validation and metrics  
- 🧪 Inference code to predict masks for unseen images

---

## 🎯 Competition Source  
This project was built using the dataset from the [Carvana Image Masking Challenge on Kaggle](https://www.kaggle.com/competitions/carvana-image-masking-challenge).

---
## ⚙️ Training Setup & 📊 Evaluation Metrics

Due to hardware limitations (Mac M1 Air), the input images were resized from their original resolution to **240×160** during training and inference.  
Despite the downscaling, the model achieved strong results.

### 🔧 Training Details
- **Model**: U-Net (from scratch using PyTorch)
- **Input Size**: 240×160
- **Loss Function**: BCEWithLogitsLoss
- **Optimizer**: Adam
- **Augmentations**: Resize, Rotate, Horizontal Flip (using Albumentations)
- **Hardware**: macOS M1 Air (CPU/MPS)

### 📏 Evaluation Metrics
During validation, the model was evaluated using:

- **Pixel Accuracy**: Measures how many pixels were correctly classified overall.
- **Dice Score**: A metric used for image segmentation:
`Dice = (2 × |Prediction ∩ GroundTruth|) / (|Prediction| + |GroundTruth|)`

### 📝 Results on Validation Set

| Metric          | Value        |
|------------------|--------------|
| Pixel Accuracy   | 99.44%       |
| Dice Score       | 0.986        |

> 💡 *Note:* You can achieve even better results by training on higher-resolution images (e.g. 512×512) and using a GPU-based environment.

---
## 🖼️ Sample Predictions

Here are some example predictions generated by the model:

| Ground Truth  | Predicted Mask |
|-------------|----------------|
| ![Mask](saved_images/mask_0.png) | ![Input](saved_images/pred_0.png)|


> You can find all predicted masks inside the `saved_images/` folder after running `predict.py`.
--
## 📁 Folder Structure

Here's a quick overview of the main files and folders in the project:

```bash

├── data/                         # Folder containing training and validation images & masks
│   ├── train/
│   ├── train_masks/
│   ├── data_validation/
│   └── data_validation_masks/
├── saved_images/                # Output folder for predicted masks
├── Model.py                     # U-Net model architecture
├── dataset.py                   # Custom Dataset class
├── train.py                     # Training pipeline
├── test.py                      # Evaluation or prediction script
├── utils.py                     # Helper functions (metrics, plotting, etc.)
├── requirements.txt             # Python dependencies
```

## 🔗 Pretrained Weights

Download the pretrained model checkpoint here: [Google Drive link](https://drive.google.com/file/d/1vhwpv_wTyPrgY_KHs4jMepkcNRaUlvwR/view?usp=share_link) 


## 📦 Dataset

You can download the dataset required for training and validation from the link below:  👉 [Download Dataset from Google Drive](https://drive.google.com/file/d/1H3MWmNQTnY3nssauDrntniGEhkTMk_eD/view?usp=share_link)

> 💡 Make sure to extract the dataset and place it in the `data/` directory.

## 🚀 How to Run

1. **Install dependencies**
```bash
pip install -r requirements.txt
```

2. **Train the model**
```bash
python train.py
```
3. **Run inference on test image**
```bash
python test.py
```
4. **Output**
  🖼️ The predicted masks will be saved in the saved_images/ folder

## 💬 Notes
	•	The model uses BCEWithLogitsLoss for binary segmentation.
	•	Mixed precision training (AMP) is supported for faster training on GPUs.
	•	Image augmentation is applied using Albumentations.



